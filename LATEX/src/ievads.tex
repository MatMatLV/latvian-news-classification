Mūsdienās internets ir kļuvis par galveno informācijas avotu lielai daļai cilvēku, kuri ikdienā ar dažādu mediju palīdzību caur to gūst informāciju par jaunākajām aktualitātēm savā rajonā, valstī un pasaulē. Svarīga loma informācijas iegūšanā un izplatīšanā ir arī pareizai teksta klasifikācijai, lai šī informācija sasniegtu vēlamo lasītāju. Pārsvarā problēma tiek atrisināta autoram klasificējot savu darbu jau izveides procesā, tomēr bieži ar to vien nepietiek – tiek pārpublicēti raksti no ārējiem resursiem, mainās kategoriju iedalījums, aktuālas kļūst jaunas tēmas u.t.t. Lai gan arī šādos gadījumos klasifikāciju iespējams darīt manuāli, pie liela informācija apjoma kļūst jēgpilni šo klasifikāciju automatizēt ar mašīnmācīšanās algoritmiem, ietaupot laiku un resursus. 

Pirms darba uzsākšanas, veicot izpēti par labākajiem algoritmiem tekstu klasifikācijai, konstatēts, ka viennozīmīgi labākā pieeja problēmas risināšanai neekstistē, optimālā pieeja atkarīga no daudziem faktoriem – gan no dažādām datu kopas īpašībām (valoda, temati, tekstu garumi, valodas stili u.t.t.), gan klašu skaita klasifikācijā, gan pielietotajām priekšapstrādes metodēm, gan cik labi algoritmi mērogojas ar dažādiem datu kopu izmēriem. Līdzīgu ieskatu vispārējā problēmvidē sniedz arī “Papers With Code”\footnote{https://paperswithcode.com/task/text-classification}, kas apkopo ar mašīnmācīšanos saistītās publikācijas un tajos iekļauto modeļu veiktspējas rādītājus, to starpā arī 1091 publikācijas par tekstu klasifikāciju. Šajā resursā iespējams novērot, ka pēdējos gados labākos rezultātus pārsvarā, bet ne vienmēr, sniedz lielo valodu modeļi kā XLNet un BERT. Konkrēti šos iepriekš apmācītos modeļus nav iespējams pielietot latviešu tekstu klasifikācijai - šie modeļi ir apmācīti uz ļoti liela angļu valodas tekstu apjoma - BERT gadījumā 3,3 miljardu vārdu korpusa, XLNet gadījumā - jau krietni lielāka. Salīdzinoši lielākais latviešu valodas korpuss šobrīd (LVK2022\footnote{https://korpuss.lv/id/LVK2022}) satur tikai 101 miljonu vārdu. Nākošo labāko algoritmu veiktspējas atšķirības kļūst mazāk izteiktas – labus rezultātus sasniedz gan dažādas rekurento neironu tīklu arhitektūras (LSTM balstīti modeļi), gan konvolūcijas neironu tīkli, gan arī vienkāršākas pieejas kā atbalsta vektora mašīnas. Šo secinājumu rezultātā izlemts izpētīt cik labi klasifikāciju iespējams veikt ar plašu spektru ar klasifikācijas metodēm – sākot no vienkāršiem klasifikācijas algoritmiem kā Naivā Bajesa metode, atbalsta vektora mašīnas u.c., turpinot ar dažādām neironu tīklu arhitektūrām, kā arī pielāgojot BERT arhitektūrā balstīto LVBERT modeli. 

Darba mērķis ir izveidot mašīnmācīšanās modeli, kas ar augstu precizitāti spētu klasificēt ziņu portālu rakstus latvieu valodā. Lai sasniegtu šo mērķi, tiek izvirzīti sekojoši uzdevumi:
\begin{enumerate}
\item Veikt literatūras izpēti par mašīnmācīšanos un tekstu klasifikāciju
\item Izveidot rāpuli ar kura palīdzību izgūt un marķēt ziņu portālu rakstus, pielietojamus modeļu apmācībā
\item Implementēt dažādus mašīnmācīšanās algoritmus tekstu klasifikācijai
\item Izpētīt kā dažādas pazīmju ģenerēšanas pieejas ietekmē klasifikācijas rezultātus
\item Veikt precizitātes novērtējumus un salīdzināt cik labi dažādos algoritmos balstīti modeļi spēj veikt latviešu valodas tekstu klasifikāciju
\end{enumerate}

Lai veiktu algoritmu implementēšanu un analīzi tiks izmantota programmēšanas valoda Python un plaši pielietotas bibliotēkas mašīnmācīšanās problēmu risināšanai (scikit-learn, Tensorflow).

Darbs sastāv no 4 nodaļām. Pirmajā nodaļā tiek apskatīta dabiskās valodas apstrāde un mašīnmācīšanās, pamatjēdzieni uz kuriem balstās nākošo nodaļu saturs.

Otrajā nodaļā uzsvars tiek likts uz pazīmju ģenerēšanas aprakstu un literatūras izpēti par to. Šis ir svarīgs solis pirms mašīnmācīšanās algoritmu pielietošanas, pārvēršot teksta informāciju apstrādei piemērotā formā un ietekmējot to cik veiksmīgu modeli būs iespējams izveidot.

Trešajā nodaļā konkrēti tiek apskatīti dažādi izplatītākie algoritmi ar kuriem veikt teksta klasifikāciju – sākot no vienkāršākām pieejām kā atbalsta vektora mašīnas, turpinot ar neironu tīkliem un lielajiem valodas modeļiem kā BERT.

Ceturtajā nodaļā tiek apskatīta rāpuļa un klasifikācijas modeļu praktiskā izveide, cik labi dažādi modeļi spēja sasniegt vēlamo rezultātu.
